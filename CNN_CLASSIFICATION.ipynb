{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_CLASSIFICATION.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOCXHza3zmdf1496zlqCApu"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kbt_9184rz5V"
      },
      "source": [
        "## `*Importing required packages*`  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4S8N5zUrmXn"
      },
      "source": [
        "import numpy as np\n",
        "import math,cv2,os\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "#from keras.backend.tensorflow_backend import set_session\n",
        "from tensorflow.python.keras.backend import set_session\n",
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth=True\n",
        "#config = tf.compat.v1.configProto(device_count = {'GPU' : 0, 'CPU' : 56})\n",
        "sess = tf.compat.v1.Session(config = config)\n",
        "from keras import backend as K\n",
        "#tf.compat.v1.keras.backend.get_session(sess)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydn3kqIUryi8"
      },
      "source": [
        "# Data *Input*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkwRlrAFsPSU"
      },
      "source": [
        "train_dataset_path = \"Train/\"\n",
        "test_dataset_path = \"Test/\"\n",
        "in_dir = 'Data/'\n",
        "Categories = ['One', 'Two']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWIV0ujNs-ve"
      },
      "source": [
        "## Train & Test Data Generator  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIcCcizasdeo"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "training_set = train_datagen.flow_from_directory(in_dir+train_dataset_path,\n",
        "target_size = (64,64), \n",
        "class_mode = 'categorical')\n",
        "test_set = test_datagen.flow_from_directory(in_dir+test_dataset_path,\n",
        "target_size = (64,64),\n",
        "batch_size = 32,\n",
        "color_mode = 'rgb',\n",
        "shuffle = True,\n",
        "seed = None,\n",
        "class_mode = 'categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYSEWAA7tH67"
      },
      "source": [
        "## Architecture of CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcrqITdMtdhh"
      },
      "source": [
        "INPUT_SHAPE = (64, 64, 3) # change to (SIZE, SIZE, 3)\n",
        "inp = keras.layers.Input(shape=INPUT_SHAPE)\n",
        "conv1 = keras.layers.Conv2D(32, kernel_size=(3, 3),\n",
        " activation='relu', padding='same')(inp)\n",
        "pool1 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "norm1 = keras.layers.BatchNormalization(axis=-1)(pool1)\n",
        "drop1 = keras.layers.Dropout(rate=0.3)(norm1)\n",
        "\n",
        "conv2 = keras.layers.Conv2D(32, kernel_size=(3, 3),\n",
        " activation='relu', padding='same')(drop1)\n",
        "pool2 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "norm2 = keras.layers.BatchNormalization(axis=-1)(pool2)\n",
        "drop2 = keras.layers.Dropout(rate=0.3)(norm2)\n",
        "flat = keras.layers.Flatten()(norm2) # Flatten the matrix to get it ready for dense.\n",
        "hidden1 = keras.layers.Dense(512, activation='relu')(flat)\n",
        "norm3 = keras.layers.BatchNormalization(axis=-1)(hidden1)\n",
        "drop3 = keras.layers.Dropout(rate=0.3)(norm3)\n",
        "\n",
        "hidden2 = keras.layers.Dense(256, activation='relu')(drop3)\n",
        "norm4 = keras.layers.BatchNormalization(axis=-1)(hidden2)\n",
        "drop4 = keras.layers.Dropout(rate=0.3)(norm3)\n",
        "out = keras.layers.Dense(2, activation='softmax')(drop4) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJyWdMy3tgp8"
      },
      "source": [
        "### Model summery "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg58fJ4ktfyC"
      },
      "source": [
        "model = keras.Model(inputs=inp, outputs=out)\n",
        "model.compile(optimizer='adam',\n",
        "loss='categorical_crossentropy', # Check between binary_crossentropy and categorical_crossentropy\n",
        " metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUbZJTOwtrLS"
      },
      "source": [
        "### Training Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrm6ynVutr0s"
      },
      "source": [
        "history = model.fit(training_set,\n",
        " validation_data = test_set,\n",
        " batch_size=64,\n",
        " verbose=1,\n",
        " epochs=20,\n",
        " shuffle=True\n",
        "# callbacks=callbacks\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYaqKt38t2Cv"
      },
      "source": [
        "### mModel evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWTHYlX4t1CC"
      },
      "source": [
        "score = model.evaluate(training_set,verbose=1)\n",
        "print(\"Testing loss: \",score[0])\n",
        "print(\"Testing Accuracy :\", score[1]*100)\n",
        "\n",
        "\n",
        "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "t = f.suptitle('CNN Performance', fontsize=12)\n",
        "f.subplots_adjust(top=0.85, wspace=0.3)\n",
        "\n",
        "max_epoch = len(history.history['accuracy']) + 1\n",
        "epoch_list = list(range(1, max_epoch))\n",
        "ax1.plot(epoch_list, history.history['accuracy'], label='Train Accuracy')\n",
        "ax1.plot(epoch_list, history.history['val_accuracy'], label='Validation Accuracy')\n",
        "ax1.set_xticks(np.arange(1, max_epoch, 5))\n",
        "ax1.set_ylabel('Accuracy Value')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_title('Accuracy')\n",
        "l1 = ax1.legend(loc=\"best\")\n",
        "\n",
        "ax2.plot(epoch_list, history.history['loss'], label='Train Loss')\n",
        "ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\n",
        "ax2.set_xticks(np.arange(1, max_epoch, 5))\n",
        "ax2.set_ylabel('Loss Value')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_title('Loss')\n",
        "l2 = ax2.legend(loc=\"best\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYM-aK5Wt0xw"
      },
      "source": [
        ""
      ]
    }
  ]
}